# -*- coding: utf-8 -*-
"""Mofa_with_Nan_pipline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_v17wiMIasHj3Dl0xTCUfNYRf8r4dCF1

# Import Tools
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import torch.nn.functional as F
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
torch.manual_seed(42)
np.random.seed(42)
from torch_geometric.nn import GATConv, GCNConv
from torch_geometric.data import Data
from torch_geometric.nn import knn_graph
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.feature_selection import VarianceThreshold
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

"""# Load Pre-processed Data from CSV Files"""

print("Loading pre-processed datasets from CSV files...")

# Load the preprocessed omics data
expression_data_scaled = pd.read_csv("NewDatasets/expression_data_scaled_FXS_MOFA_3Omics.csv", index_col=0)
methylation_scaled = pd.read_csv("NewDatasets/methylation_scaled_FXS_MOFA_3Omics.csv", index_col=0)
copy_number_scaled = pd.read_csv("NewDatasets/copy_number_scaled_FXS_MOFA_3Omics.csv", index_col=0)
subtype_encoded = pd.read_csv("NewDatasets/subtype_encoded_FXS_MOFA_3Omics.csv", index_col=0).squeeze()
phenotype_data_clean = pd.read_csv("NewDatasets/phenotype_data_clean_FXS_MOFA_3Omics.csv", index_col=0)

# Extract common samples from the loaded data
common_samples = list(expression_data_scaled.columns)

print("‚úÖ Pre-processed data loaded successfully!")
print()
print("Data shapes:")
print(f"  Expression: {expression_data_scaled.shape}")
print(f"  Methylation: {methylation_scaled.shape}")
print(f"  Copy Number: {copy_number_scaled.shape}")
print(f"  Phenotype: {phenotype_data_clean.shape}")
print(f"  Subtype labels: {subtype_encoded.shape}")
print(f"  Common samples: {len(common_samples)}")

print("Missing values before MOFA:")
print(f"Expression: {expression_data_scaled.isnull().sum().sum()}")
print(f"Methylation: {methylation_scaled.isnull().sum().sum()}")
print(f"Copy number: {copy_number_scaled.isnull().sum().sum()}")

from mofapy2.run.entry_point import entry_point

data_list = [
    [expression_data_scaled.T.values],   # view 0, group 0
    [methylation_scaled.T.values],       # view 1, group 0
    [copy_number_scaled.T.values]       # view 2, group 0
]

# Initialise MOFA
ent = entry_point()
ent.set_data_options(
    scale_views=True,
    scale_groups=False
)
ent.set_data_matrix(data_list)

ent.set_model_options(
    factors=14,
    spikeslab_factors=True,
    spikeslab_weights=True,
    ard_factors=True,
    ard_weights=True
)

# Training options
ent.set_train_options(
    iter=400,
    convergence_mode="slow",
    seed=42,
    verbose=True,
    gpu_mode=True
)

# Build and run
ent.build()
ent.run()

# Extract results
factors = ent.model.nodes["Z"].getExpectation()
weights = ent.model.nodes["W"].getExpectation()

print("Factors shape",factors.shape)
print("Weights shape (view0):", weights[0].shape)
print("Weights shape (view1):", weights[1].shape)
print("Weights shape (view2):", weights[2].shape)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# factors is already (n_samples √ó n_factors)
factor_array = np.array(factors)

# If you ever had only one sample, this ensures it's 2D
if factor_array.ndim == 1:
    factor_array = factor_array.reshape(1, -1)

plt.figure(figsize=(10, 6))
sns.heatmap(factor_array, cmap='viridis', annot=False)
plt.xlabel('Factor')
plt.ylabel('Sample')
plt.title('MOFA Factor Heatmap')
plt.tight_layout()
plt.show()

from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, random_state=42)
factors_2d = tsne.fit_transform(factors)

plt.figure(figsize=(7,6))
plt.scatter(factors_2d[:,0], factors_2d[:,1], c=subtype_encoded.values, cmap="tab10", alpha=0.7)
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.title("t-SNE of MOFA factors")
plt.colorbar(label="Class")
plt.show()

#kmeans clustering on the factors
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=3)
kmeans.fit(factors)
labels = kmeans.labels_
plt.figure(figsize=(7,6))
plt.scatter(factors_2d[:,0], factors_2d[:,1], c=labels, cmap="tab10", alpha=0.7)
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.title("K-means Clustering on MOFA factors")
plt.colorbar(label="Cluster")
plt.show()

import numpy as np

# Get factor matrix (samples √ó factors)
factors = ent.model.nodes["Z"].getExpectation()

# Compute L2 norm of each factor across samples
factor_norms = np.linalg.norm(factors, axis=0)

print("Factor norms:", factor_norms)
active_factors = np.sum(factor_norms > 1e-2)  # threshold can be adjusted
print(f"Active factors: {active_factors} / {factors.shape[1]}")

# ===============================================
# MOFA CLUSTER QUALITY EVALUATION METRICS
# ===============================================

from sklearn.metrics import (silhouette_score, adjusted_rand_score,
                           normalized_mutual_info_score, adjusted_mutual_info_score,
                           homogeneity_completeness_v_measure, calinski_harabasz_score,
                           davies_bouldin_score)
from sklearn.metrics.cluster import contingency_matrix
import numpy as np
import pandas as pd

print("üîç MOFA CLUSTER QUALITY EVALUATION")
print("=" * 50)

# 1. INTERNAL CLUSTERING METRICS (using MOFA factors)
print("\nüìä INTERNAL CLUSTERING METRICS:")
print("-" * 30)

# Silhouette Score (Higher is better, range: -1 to 1)
sil_score = silhouette_score(factors, labels)
print(f"Silhouette Score: {sil_score:.4f}")

# Calinski-Harabasz Score (Higher is better)
ch_score = calinski_harabasz_score(factors, labels)
print(f"Calinski-Harabasz Score: {ch_score:.4f}")

# Davies-Bouldin Score (Lower is better)
db_score = davies_bouldin_score(factors, labels)
print(f"Davies-Bouldin Score: {db_score:.4f}")

# 2. EXTERNAL VALIDATION METRICS (comparing with true subtypes)
print("\nüéØ EXTERNAL VALIDATION METRICS:")
print("-" * 30)

# Convert true labels to match clustering labels format
true_labels = subtype_encoded.values.flatten()

# Adjusted Rand Index (Higher is better, range: -1 to 1)
ari_score = adjusted_rand_score(true_labels, labels)
print(f"Adjusted Rand Index: {ari_score:.4f}")

# Normalized Mutual Information (Higher is better, range: 0 to 1)
nmi_score = normalized_mutual_info_score(true_labels, labels)
print(f"Normalized Mutual Information: {nmi_score:.4f}")

# Adjusted Mutual Information (Higher is better, range: -1 to 1)
ami_score = adjusted_mutual_info_score(true_labels, labels)
print(f"Adjusted Mutual Information: {ami_score:.4f}")

# Homogeneity, Completeness, V-measure
homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(true_labels, labels)
print(f"Homogeneity: {homogeneity:.4f}")
print(f"Completeness: {completeness:.4f}")
print(f"V-measure: {v_measure:.4f}")

# 3. CLUSTER COMPOSITION ANALYSIS
print("\nüìà CLUSTER COMPOSITION ANALYSIS:")
print("-" * 30)

# Create contingency table
cont_matrix = contingency_matrix(true_labels, labels)
print("Contingency Matrix (True Labels vs Predicted Clusters):")
print(cont_matrix)

# Cluster purity
cluster_purity = np.sum(np.max(cont_matrix, axis=0)) / np.sum(cont_matrix)
print(f"\nCluster Purity: {cluster_purity:.4f}")

# 4. FACTOR QUALITY METRICS
print("\nüî¨ MOFA FACTOR QUALITY METRICS:")
print("-" * 30)

# Factor variance explained
factor_variance = np.var(factors, axis=0)
total_variance = np.sum(factor_variance)
variance_explained = factor_variance / total_variance * 100

print("Factor Variance Explained (%):")
for i, var_exp in enumerate(variance_explained):
    print(f"  Factor {i+1}: {var_exp:.2f}%")

print(f"\nTop 5 factors explain: {np.sum(variance_explained[:5]):.2f}% of variance")

# Factor separability (mean distance between cluster centroids)
unique_labels = np.unique(labels)
centroids = []
for label in unique_labels:
    centroid = np.mean(factors[labels == label], axis=0)
    centroids.append(centroid)

centroids = np.array(centroids)
pairwise_distances = []
for i in range(len(centroids)):
    for j in range(i+1, len(centroids)):
        dist = np.linalg.norm(centroids[i] - centroids[j])
        pairwise_distances.append(dist)

mean_centroid_distance = np.mean(pairwise_distances)
print(f"Mean Inter-cluster Distance: {mean_centroid_distance:.4f}")

# 5. OVERALL QUALITY SUMMARY
print("\nüèÜ OVERALL QUALITY SUMMARY:")
print("-" * 30)

# Create a composite score (weighted average of key metrics)
composite_score = (
    0.3 * sil_score +           # Internal consistency
    0.3 * ari_score +           # Agreement with true labels
    0.2 * nmi_score +           # Information shared with true labels
    0.2 * cluster_purity        # Cluster purity
)

print(f"Composite Quality Score: {composite_score:.4f}")

# Quality interpretation
if composite_score > 0.7:
    quality_rating = "Excellent"
elif composite_score > 0.5:
    quality_rating = "Good"
elif composite_score > 0.3:
    quality_rating = "Fair"
else:
    quality_rating = "Poor"

print(f"Overall Rating: {quality_rating}")

print("\nüí° INTERPRETATION GUIDE:")
print("- Silhouette Score: >0.7=Excellent, 0.5-0.7=Good, 0.25-0.5=Fair, <0.25=Poor")
print("- ARI: >0.9=Excellent, 0.8-0.9=Good, 0.6-0.8=Fair, <0.6=Poor")
print("- NMI: >0.9=Excellent, 0.7-0.9=Good, 0.5-0.7=Fair, <0.5=Poor")

# PCA plots for all 15 MOFA factors
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# factors: (n_samples, n_factors)
factors_array = np.array(factors)
labels = subtype_encoded.loc[common_samples].values

pca = PCA(n_components=2)

fig, axes = plt.subplots(5, 3, figsize=(18, 24))
axes = axes.flatten()

for i in range(12):
    # For each factor, use all factors for PCA, but color by the i-th factor
    pca_result = pca.fit_transform(factors_array)
    ax = axes[i]
    scatter = ax.scatter(pca_result[:,0], pca_result[:,1], c=factors_array[:,i], cmap='viridis', alpha=0.7)
    ax.set_title(f'PCA of MOFA Factors (Factor {i+1} coloring)')
    ax.set_xlabel('PC1')
    ax.set_ylabel('PC2')
    plt.colorbar(scatter, ax=ax, label=f'Factor {i+1}')

plt.tight_layout()
plt.show()

# ===============================================
# PATIENT MANIFOLD LEARNING & DIFFUSION
# ===============================================

import networkx as nx
from sklearn.neighbors import NearestNeighbors
from scipy.spatial.distance import pdist, squareform

print("\nRunning Patient Manifold Learning & Diffusion Steps...")

# 1. Choose similarity metric & 2. Construct adjacency matrix A
def get_similarity_and_adjacency(latent_data, k=10, metric='euclidean', sigma_scale=1.0):
    n = latent_data.shape[0]
    
    if metric == 'euclidean':
        # Pairwise Euclidean distances
        dists = squareform(pdist(latent_data, 'euclidean'))
        
        # Heuristic for sigma: median distance
        sigma = np.median(dists) * sigma_scale
        if sigma == 0: sigma = 1.0
        
        # Convert to similarity: sim = exp(-d^2 / sigma^2)
        similarity = np.exp(- (dists ** 2) / (sigma ** 2))
        
    elif metric == 'correlation':
        # Pearson correlation
        similarity = np.corrcoef(latent_data)
        # Shift to [0,1] or take abs, assuming manifold connection for high similarity
        similarity = (similarity + 1) / 2
        
    else:
        raise ValueError("Unsupported metric")
    
    # k-NN connection
    # Use sklearn for efficient neighbor search
    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(latent_data)
    distances, indices = nbrs.kneighbors(latent_data)
    
    A = np.zeros((n, n))
    for i in range(n):
        for j_idx in range(1, k + 1): # Skip self (index 0)
            neighbor = indices[i, j_idx]
            A[i, neighbor] = similarity[i, neighbor]
            
    return A, similarity

# Parameters
k_neighbors = 10
# Using Euclidean distance converted to similarity as requested
try:
    if 'factors' in globals():
        pass
    elif 'factors' in locals():
        pass
    else:
        # Fallback if factors variable name changed or not found (unlikely)
        print("Warning: 'factors' variable not found. Using random data for demo if not present.")
        # factors = np.random.rand(100, 10) 

    A, Sim = get_similarity_and_adjacency(factors, k=k_neighbors, metric='euclidean')

    # 3. Make graph symmetric: A = max(A, A.T)
    A_sym = np.maximum(A, A.T)

    # 4. Optional: Normalize adjacency for diffusion (Normalized Laplacian)
    # L_norm = D^-0.5 * L * D^-0.5
    def get_normalized_laplacian(Adj):
        degree = np.sum(Adj, axis=1)
        degree[degree == 0] = 1e-10 # Avoid division by zero
        
        D_inv_sqrt = np.diag(np.power(degree, -0.5))
        L = np.diag(degree) - Adj
        
        L_norm = D_inv_sqrt @ L @ D_inv_sqrt
        return L_norm

    L_norm = get_normalized_laplacian(A_sym)
    print("Computed Normalized Laplacian L_norm.")

    # 5. Graph inspection
    # Visualize graph: nodes = patients, edges = similarity
    # Color nodes by subtype
    def visualize_patient_network(Adj, labels=None, title="Patient Similarity Network"):
        G = nx.from_numpy_array(Adj)
        
        # Use spring layout (Fruchterman-Reingold) which simulates diffusion/springs
        pos = nx.spring_layout(G, seed=42)
        
        plt.figure(figsize=(10, 8))
        
        # Draw nodes
        color_map = labels if labels is not None else 'skyblue'
        
        nx.draw_networkx_nodes(G, pos, 
                            node_size=60, 
                            node_color=color_map, 
                            cmap='tab10' if labels is not None else None, 
                            alpha=0.9)
        
        # Draw edges
        nx.draw_networkx_edges(G, pos, alpha=0.3, width=0.5, edge_color='gray')
        
        plt.title(title)
        plt.axis('off')
        plt.show()

    # Use the subtype labels we prepared earlier
    # subtype_encoded is a Series, we want values
    if 'subtype_encoded' in globals() or 'subtype_encoded' in locals():
        # Make sure align with factors samples if needed, but factors implies common samples
        # checks if ordering is preserved. The script preserves order.
        if hasattr(subtype_encoded, 'values'):
             # if subtype_encoded is full dataset, we must filter by common_samples if factors corresponds to common_samples
             # Check logic in script: factors comes from ent.run(). ent uses data_list which is expression_data_scaled which is filtered to common_samples.
             # subtype_encoded is also filtered to valid_samples (common_samples).
             # So they should align.
             labels_for_plot = subtype_encoded.values
        else:
             labels_for_plot = subtype_encoded
             
        visualize_patient_network(A_sym, labels_for_plot, title=f"Patient Manifold (k={k_neighbors})")
    else:
        print("Warning: subtype_encoded not found, skipping visualization coloring.")
        visualize_patient_network(A_sym, None, title=f"Patient Manifold (k={k_neighbors})")

except Exception as e:
    print(f"Error in Patient Graph Construction: {e}")

# ===============================================
# CLASS PROTOTYPE DIFFUSION
# ===============================================

print("\nRunning Class Prototype Diffusion...")
from scipy.linalg import expm, inv
import seaborn as sns

try:
    # Ensure necessary variables are available
    if 'factors' not in locals():
        print("Error: 'factors' (latent representations) not found.")
        # raise ValueError("Missing factors") # Don't raise, just skip to avoid crashing entire script if re-run
    if 'subtype_encoded' not in locals():
        print("Error: 'subtype_encoded' (class labels) not found.")
        # raise ValueError("Missing subtype_encoded")
    if 'A_sym' not in locals():
        try:
            # Try to recover A_sym if it was created in the previous scope but not saved globally
            # In notebook-like scripts, locals() might scope out. 
            # Re-create if needed or check assuming it ran.
            pass
        except:
            print("Error: 'A_sym' (symmetric adjacency matrix) not found.")
        
    # 1. Compute Naive Class Prototypes
    # ---------------------------------
    # Compute centroid of each class in latent space (Z)
    if 'subtype_encoded' in locals() and 'factors' in locals():
        unique_classes = np.unique(subtype_encoded.values)
        naive_prototypes = {}
        
        print("\n1. Naive Class Prototypes (Centroids in Latent Space):")
        for cls in unique_classes:
            # Get indices of patients in this class
            cls_indices = np.where(subtype_encoded.values == cls)[0]
            
            # Compute mean of factors for these patients
            cls_factors = factors[cls_indices]
            centroid = np.mean(cls_factors, axis=0)
            naive_prototypes[cls] = centroid
            print(f"   Class {cls}: Computed centroid from {len(cls_indices)} patients.")

        # 2. Diffusion of Prototypes along Graph
        # --------------------------------------
        # We interpret "diffusing prototypes" as propagating the class influence/signal across the patient manifold.
        # We treat the initial class assignment as a signal on the graph (Indicator Vector) and diffuse it.
        
        # Prepare Class Indicator Matrix (Signal)
        n_samples = factors.shape[0]
        n_classes = len(unique_classes)
        class_signals = np.zeros((n_samples, n_classes))
        
        for i, cls in enumerate(unique_classes):
            class_signals[subtype_encoded.values == cls, i] = 1.0
            
        # Define Diffusion Functions
        
        def heat_kernel_diffusion(signal, L_norm_matrix, alpha=0.5):
            """
            Option A: Heat kernel diffusion
            diffused_signal = exp(-alpha * L) @ signal
            """
            print(f"   Computing Matrix Exponential (Heat Kernel) with alpha={alpha}...")
            # expm is computationally expensive for large N, but N=183 is small and fine.
            H = expm(-alpha * L_norm_matrix) 
            diffused = H @ signal
            return diffused, H
            
        def random_walk_diffusion(signal, Adj_matrix, alpha=0.5):
            """
            Option B: Random walk diffusion
            diffused_signal = (I - alpha * W)^(-1) @ signal
            W = D^-1 * A (Row normalized adjacency)
            """
            print(f"   Computing Random Walk Diffusion with alpha={alpha}...")
            # Compute W (Row Normalized)
            degree = np.sum(Adj_matrix, axis=1)
            degree[degree == 0] = 1e-10
            D_inv = np.diag(1.0 / degree)
            W = D_inv @ Adj_matrix
            
            I = np.eye(Adj_matrix.shape[0])
            
            # Matrix Inversion: (I - alpha * W)^-1
            # This is equivalent to solving linear system or direct inversion
            M = inv(I - alpha * W)
            diffused = M @ signal
            return diffused, M

        # Execute Diffusion
        # Note: Using L_norm_matrix computed in previous step if available
        
        if 'L_norm' in locals():
            # Option A: Heat Kernel
            diffused_signals_heat, HeatKernel = heat_kernel_diffusion(class_signals, L_norm, alpha=0.5)
            
            # Visualize Result for one class
            plt.figure(figsize=(12, 5))
            plt.subplot(1, 2, 1)
            sns.heatmap(class_signals, cmap="Blues", cbar=False)
            plt.title("Original Class Signals (Hard Labels)")
            plt.xlabel("Class Index")
            plt.ylabel("Patient Index")
            
            plt.subplot(1, 2, 2)
            sns.heatmap(diffused_signals_heat, cmap="Blues", cbar=True)
            plt.title("Diffused Signals (Heat Kernel)")
            plt.xlabel("Class Index")
            plt.ylabel("Patient Index")
            plt.tight_layout()
            plt.show()
            
        else:
            print("Warning: L_norm not found. Skipping Heat Kernel Diffusion.")

        # Option B: Random Walk
        if 'A_sym' in locals():
            diffused_signals_rw, RW_Matrix = random_walk_diffusion(class_signals, A_sym, alpha=0.8) # Alpha typically 0.8-0.9 for PageRank style
            
            # 3. Interpretation / Analysis
            # ----------------------------
            print("\n3. Interpretation of Diffused Prototypes:")
            print("   The diffused signals represent the 'influence' of each class prototype on every patient.")
            print("   This respects the manifold structure of the patient graph.")
            
            # Check how much rare classes spread
            # class_counts = subtype_encoded.value_counts().sort_index()
            
            for i, cls in enumerate(unique_classes):
                original_influence = np.sum(class_signals[:, i])
                diffused_influence = np.sum(diffused_signals_rw[:, i])
                n_patients_orig = np.sum(class_signals[:, i] > 0)
                # Threshold for "soft" membership
                n_patients_diff = np.sum(diffused_signals_rw[:, i] > 1e-3) 
                
                print(f"   Class {cls} (Original Size: {n_patients_orig}):")
                print(f"     - Total Influence Mass (Original): {original_influence:.2f}")
                print(f"     - Total Influence Mass (Diffused): {diffused_influence:.2f}")
                print(f"     - Effective Reach (>0.001 signal): {n_patients_diff} patients")

            # Optional: Update Latent Factors based on Diffusion? 
            # The prompt asks for "diffused_prototype_c", which we interpreted as the influence map.
            # We could also smooth the factors themselves:
            print("\n   (Optional) Smoothing Latent Factors via Random Walk:")
            smoothed_factors = RW_Matrix @ factors
            
            # Visualize Smoothed Factors
            tsne_smooth = TSNE(n_components=2, random_state=42)
            factors_smooth_2d = tsne_smooth.fit_transform(smoothed_factors)
            
            plt.figure(figsize=(7,6))
            plt.scatter(factors_smooth_2d[:,0], factors_smooth_2d[:,1], c=subtype_encoded.values, cmap="tab10", alpha=0.7)
            plt.title("t-SNE of Diffused/Smoothed Factors")
            plt.xlabel("t-SNE 1")
            plt.ylabel("t-SNE 2")
            plt.colorbar(label="Class")
            plt.show()    
        else:
            print("Warning: A_sym not found. Skipping Random Walk Diffusion.")

except Exception as e:
    print(f"Error in Class Prototype Diffusion: {e}")
    import traceback
    traceback.print_exc()

# ===============================================
# 4. CLASSIFICATION WITH DIFFUSED PROTOTYPES
# ===============================================

print("\nRunning Classification with Diffused Prototypes...")

try:
    if 'diffused_signals_rw' not in locals():
        print("Warning: diffused_signals_rw not found. Cannot compute diffused prototypes.")
    else:
        # 1. Compute Diffused Prototypes
        # ------------------------------
        diffused_prototypes = {}
        print("\nComputing Diffused Prototypes (Weighted Centroids):")
        
        # We use the diffused class signals as weights to compute the weighted mean of factors
        # 'unique_classes' was defined in the previous block
        
        for i, cls in enumerate(unique_classes):
            # influence weights for class cls (from Random Walk)
            weights = diffused_signals_rw[:, i]
            
            # Weighted average
            # (N,) * (N, F) -> (N, F) -> sum -> (F,)
            weighted_factors = factors * weights[:, np.newaxis]
            diffused_centroid = np.sum(weighted_factors, axis=0) / (np.sum(weights) + 1e-10)
            
            diffused_prototypes[cls] = diffused_centroid
            
            # Compute shift distance from naive prototype if available
            if 'naive_prototypes' in locals():
                shift = np.linalg.norm(diffused_centroid - naive_prototypes[cls])
                print(f"   Class {cls}: Prototype shifted by {shift:.4f} in latent space.")
            else:
                 print(f"   Class {cls}: Diffused prototype computed.")

        # 2. Classification
        # -----------------
        # For each patient, calculate distance to each diffused prototype
        n_samples = factors.shape[0]
        distances = np.zeros((n_samples, len(unique_classes)))
        
        for i, cls in enumerate(unique_classes):
            proto = diffused_prototypes[cls]
            # Euclidean distance || Z - proto ||
            # simple vectorization: norm(factors - proto, axis=1)
            dist_c = np.linalg.norm(factors - proto, axis=1)
            distances[:, i] = dist_c
            
        # Hard Assignment: predicted_class = argmin_c(distance_c)
        predicted_indices = np.argmin(distances, axis=1)
        predicted_classes = unique_classes[predicted_indices]
        
        # Compare with original labels (Consistency Check)
        if 'subtype_encoded' in locals():
            true_vals = subtype_encoded.values
            acc = np.mean(predicted_classes == true_vals)
            print(f"\nRe-classification Consistency (vs Original Labels): {acc:.4%}")
            
            # Identify "misclassified" patients - these might be edge cases or transitions
            mismatches = np.where(predicted_classes != true_vals)[0]
            print(f"   Patients re-assigned to different class: {len(mismatches)} / {n_samples}")
        
        # 3. Soft Assignment / Probabilities
        # ----------------------------------
        # prob_c = exp(-distance_c) / sum(exp(-distance_all))
        # Use simple softmax on negative distances
        # For numerical stability, subtract max distance: exp(x - max)
        neg_dists = -distances
        # shift for stability
        neg_dists_shifted = neg_dists - np.max(neg_dists, axis=1, keepdims=True)
        exps = np.exp(neg_dists_shifted)
        probs = exps / np.sum(exps, axis=1, keepdims=True)
        
        print("\nSample Probabilities (First 5 patients):")
        print(pd.DataFrame(probs[:5], columns=[f"Prob_{c}" for c in unique_classes]).round(4))
        
        # 4. Interpretability
        # -------------------
        print("\nInterpretability & Analysis:")
        
        # A. Prototype Feature Importance
        # Map prototype strength back to latent factors
        print("Dominant Factors per Diffused Prototype:")
        for cls, proto in diffused_prototypes.items():
            # Get indices of top 3 absolute factors (strongest drivers)
            top_factors = np.argsort(-np.abs(proto))[:3]
            print(f"   Class {cls}: Top Factors {top_factors} (Values: {proto[top_factors].round(3)})")
            
        # B. Visualize Distributions
        # Optional: Plot probability distribution for one class
        plt.figure(figsize=(10, 5))
        for i, cls in enumerate(unique_classes):
             sns.kdeplot(probs[:, i], label=f"Class {cls}", fill=True, alpha=0.3)
        plt.title("Distribution of Soft Assignment Probabilities")
        plt.xlabel("Probability")
        plt.ylabel("Density")
        plt.legend()
        plt.show()

except Exception as e:
    print(f"Error in Classification Step: {e}")
    import traceback
    traceback.print_exc()

# ===============================================
# 5. HYPERPARAMETER TUNING (GRID SEARCH)
# ===============================================

print("\n" + "="*50)
print("HYPERPARAMETER TUNING (GRID SEARCH)")
print("="*50)

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score, accuracy_score, recall_score

# Helper function to run the full pipeline for a specific set of parameters
def evaluate_pipeline(Z, y_true, k, alpha, dist_metric='euclidean'):
    """
    Runs 5-fold CV to evaluate classification performance 
    using Manifold Learning + Diffused Prototypes.
    
    1. Graph Construction (k-NN)
    2. CV Loop:
       - Mask Test labels
       - Label Propagation (Diffusion)
       - Compute Diffused Prototypes based on Train influence
       - Classify Test nodes
    """
    
    # 1. Construct Adjacency Matrix (k-NN)
    # ------------------------------------
    # We construct the graph on the FULL dataset (Transductive assumption common in this domain)
    # Determining neighbors based on latent structure.
    # Note: Strictly inductive would require building graph only on training data and projecting test data.
    # Given N=183 and "Manifold" context, we assume we want to leverage the whole cohort structure.
    
    try:
        # Re-use the similarity function we defined earlier
        # (Assuming it's available in scope, if not we redefine locally for safety)
        if metric == 'cosine': # User asked for distance metric tuning, mapping to similarity
             # Cosine distance -> Similarity
             # 1 - cosine_distance is cosine_similarity
             # But k-NN uses distance. 
             # We use 'cosine' metric for kNN
             metric_knn = 'cosine'
        else:
             metric_knn = 'euclidean'

        nbrs_cv = NearestNeighbors(n_neighbors=k+1, metric=metric_knn).fit(Z)
        distances_cv, indices_cv = nbrs_cv.kneighbors(Z)
        
        # Build Adjacency
        n = Z.shape[0]
        A_cv = np.zeros((n, n))
        
        # Euclidean -> Similarity (Gaussian)
        # Cosine -> Similarity (1 - dist)
        if metric_knn == 'euclidean':
            sigma = np.median(distances_cv.flatten()) # heuristic
            if sigma == 0: sigma = 1.0
            sim_cv = np.exp(-(distances_cv**2) / (sigma**2))
        else:
            # Cosine distances are [0, 2]. 0 is identical.
            # Sim = 1 - dist
            sim_cv = 1 - distances_cv
            sim_cv[sim_cv < 0] = 0
            
        for i in range(n):
            for j_idx in range(1, k+1):
                neighbor = indices_cv[i, j_idx]
                A_cv[i, neighbor] = sim_cv[i, j_idx]
                
        # Symmetrize
        A_cv = np.maximum(A_cv, A_cv.T)
        
        # Random Walk Matrix: W = D^-1 * A
        deg = np.sum(A_cv, axis=1)
        deg[deg==0] = 1e-10
        D_inv = np.diag(1/deg)
        W_cv = D_inv @ A_cv
        
        # Diffusion Operator: (I - alpha*W)^-1
        I = np.eye(n)
        Diffusion_Op = inv(I - alpha * W_cv)
        
    except Exception as e:
        print(f"Graph construction failed for k={k}: {e}")
        return 0, 0, 0 # Return 0s on failure
        
    # 2. Cross Validation
    # -------------------
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    acc_scores = []
    f1_scores = []
    recall_scores = [] # Sensitivity for macro average
    
    unique_classes_cv = np.unique(y_true)
    y_true_arr = np.array(y_true)
    
    for train_idx, test_idx in skf.split(Z, y_true):
        # A. Setup Signal (Training Labels Only)
        # --------------------------------------
        signal_cv = np.zeros((n, len(unique_classes_cv)))
        for i, cls in enumerate(unique_classes_cv):
            # Only activate TRAIN nodes for this class
            # We want to diffuse the "Training Class Labels" to the network
            cls_mask = (y_true_arr[train_idx] == cls)
            # Map back to global indices
            global_train_indices_cls = train_idx[cls_mask]
            signal_cv[global_train_indices_cls, i] = 1.0
            
        # B. Diffuse Signal
        # -----------------
        # Propagate training labels to the whole graph (including test nodes)
        diffused_signal_cv = Diffusion_Op @ signal_cv
        
        # C. Compute Diffused Prototypes (Weighted by Training Influence)
        # -------------------------------------------------------------
        # We calculate prototypes using the diffused influence on TRAIN nodes?
        # Or do we use the *result* of diffusion to classify?
        # The prompt method 4.1 says: distance to diffused prototype.
        # "Diffused Prototype" = Weighted Mean of Z using diffused_signal weights.
        
        # We should compute the prototype based on the signal distribution over the network.
        # Using ALL nodes weighted by the diffused training signal allows the prototype
        # to move towards the manifold structure populated by test nodes too.
        
        diffused_prototypes_cv = {}
        for i, cls in enumerate(unique_classes_cv):
            weights = diffused_signal_cv[:, i]
            # Weighted Centroid
            weighted_Z = Z * weights[:, np.newaxis]
            centroid = np.sum(weighted_Z, axis=0) / (np.sum(weights) + 1e-10)
            diffused_prototypes_cv[cls] = centroid
            
        # D. Predict Test Nodes
        # ---------------------
        distances_test = np.zeros((len(test_idx), len(unique_classes_cv)))
        Z_test = Z[test_idx]
        
        for i, cls in enumerate(unique_classes_cv):
            proto = diffused_prototypes_cv[cls]
            # Distance
            d = np.linalg.norm(Z_test - proto, axis=1)
            distances_test[:, i] = d
            
        preds_indices = np.argmin(distances_test, axis=1)
        preds = unique_classes_cv[preds_indices]
        
        # E. Score
        # --------
        y_test = y_true_arr[test_idx]
        
        acc_scores.append(accuracy_score(y_test, preds))
        f1_scores.append(f1_score(y_test, preds, average='macro')) # Macro for small classes
        recall_scores.append(recall_score(y_test, preds, average='macro'))
        
    return np.mean(acc_scores), np.mean(f1_scores), np.mean(recall_scores)

# Run Grid Search
# ---------------

# Parameter Grid
k_values = [5, 10, 15]
alpha_values = [0.1, 0.5, 0.8, 0.99]
metrics = ['euclidean', 'cosine']

results = []

if 'subtype_encoded' in locals() and 'factors' in locals():
    y_data = subtype_encoded.values
    Z_data = factors
    
    print(f"{'Metric':<10} | {'k':<5} | {'Alpha':<5} | {'Acc':<8} | {'Mac-F1':<8} | {'Recall':<8}")
    print("-" * 65)
    
    best_score = -1
    best_params = {}
    
    for metric in metrics:
        for k in k_values:
            for alpha in alpha_values:
                acc, f1, rec = evaluate_pipeline(Z_data, y_data, k, alpha, metric)
                
                print(f"{metric:<10} | {k:<5} | {alpha:<5} | {acc:.4f}   | {f1:.4f}   | {rec:.4f}")
                
                results.append({
                    'metric': metric, 'k': k, 'alpha': alpha,
                    'acc': acc, 'f1': f1, 'recall': rec
                })
                
                # Selecting best based on Macro F1 (to balance rare classes)
                if f1 > best_score:
                    best_score = f1
                    best_params = {'metric': metric, 'k': k, 'alpha': alpha}

    print("-" * 65)
    print(f"üèÜ Best Parameters (Macro F1): {best_params}")
    print(f"   Best Score: {best_score:.4f}")

else:
    print("Skipping Grid Search: Missing 'factors' or 'subtype_encoded'.")

# ===============================================
# UTILS: CREATE OUTPUT FOLDER
# ===============================================
import os

output_folder = "results_mofa_prototype"
if not os.path.exists(output_folder):
    os.makedirs(output_folder)
    print(f"Created output folder: {output_folder}")
else:
    print(f"Output folder already exists: {output_folder}")

# ===============================================
# 6. EVALUATION AND INTERPRETATION (BEST MODEL)
# ===============================================

print("\n" + "="*50)
print("FINAL EVALUATION & INTERPRETATION")
print("="*50)

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.preprocessing import label_binarize

try:
    if 'best_params' in locals() and best_params:
        print(f"Using Best Parameters: {best_params}")
        k_best = best_params['k']
        alpha_best = best_params['alpha']
        metric_best = best_params['metric']
    else:
        print("Using default parameters (k=10, alpha=0.8, metric='euclidean') for final evaluation.")
        k_best = 10
        alpha_best = 0.8
        metric_best = 'euclidean'

    # Re-run pipeline with best params on FULL dataset (Standard stratified split for final report)
    # We will do a single 80/20 split here to show detailed metrics
    
    unique_classes_full = np.unique(subtype_encoded.values)
    
    # Stratified Split
    train_idx, test_idx = train_test_split(
        np.arange(len(subtype_encoded)), 
        test_size=0.2, 
        stratify=subtype_encoded.values, 
        random_state=42
    )
    
    # 1. Pipeline Execution (Re-implementation for final interpretation)
    # Re-build graph with best metric
    if metric_best == 'cosine':
        metric_knn = 'cosine'
    else:
        metric_knn = 'euclidean'
        
    nbrs_final = NearestNeighbors(n_neighbors=k_best+1, metric=metric_knn).fit(factors)
    dists_final, inds_final = nbrs_final.kneighbors(factors)
    
    A_final = np.zeros((factors.shape[0], factors.shape[0]))
    if metric_knn == 'euclidean':
        sigma = np.median(dists_final.flatten())
        if sigma == 0: sigma = 1.0
        sim_final = np.exp(-(dists_final**2) / (sigma**2))
    else:
        sim_final = 1 - dists_final
        sim_final[sim_final < 0] = 0
        
    for i in range(factors.shape[0]):
        for j_idx in range(1, k_best+1):
            neigh = inds_final[i, j_idx]
            A_final[i, neigh] = sim_final[i, j_idx]
            
    A_final = np.maximum(A_final, A_final.T)
    
    # Diffusion
    deg_final = np.sum(A_final, axis=1)
    deg_final[deg_final==0] = 1e-10
    D_inv_final = np.diag(1/deg_final)
    W_final = D_inv_final @ A_final
    I_final = np.eye(factors.shape[0])
    Diff_Op_Final = inv(I_final - alpha_best * W_final)
    
    # Signal Injection (Train Set only)
    signal_final = np.zeros((factors.shape[0], len(unique_classes_full)))
    y_true_all = subtype_encoded.values
    for i, cls in enumerate(unique_classes_full):
        cls_mask = (y_true_all[train_idx] == cls)
        global_train_idxs = train_idx[cls_mask]
        signal_final[global_train_idxs, i] = 1.0
        
    # Propagate
    diffused_signals_final = Diff_Op_Final @ signal_final
    
    # Prototypes
    final_prototypes = {}
    for i, cls in enumerate(unique_classes_full):
        w = diffused_signals_final[:, i]
        centroid = np.sum(factors * w[:, np.newaxis], axis=0) / (np.sum(w) + 1e-10)
        final_prototypes[cls] = centroid
        
    # Predict Test Set
    Z_test_final = factors[test_idx]
    y_test_final = y_true_all[test_idx]
    
    dists_test_final = np.zeros((len(test_idx), len(unique_classes_full)))
    for i, cls in enumerate(unique_classes_full):
        dists_test_final[:, i] = np.linalg.norm(Z_test_final - final_prototypes[cls], axis=1)
        
    # Soft scores (for AUROC)
    # Convert distances to probabilities / similarity scores
    # Score for class c = exp(-dist_c)
    scores_final = np.exp(-dists_test_final)
    # Normalize
    probs_final = scores_final / np.sum(scores_final, axis=1, keepdims=True)
    
    preds_final = unique_classes_full[np.argmin(dists_test_final, axis=1)]
    
    # ---------------------------
    # 1. Standard Metrics
    # ---------------------------
    print("\n1. Classification Report (Test Set):")
    print(classification_report(y_test_final, preds_final, zero_division=0))
    
    acc_final = accuracy_score(y_test_final, preds_final)
    print(f"Overall Accuracy: {acc_final:.4f}")
    
    # AUROC (One-vs-Rest)
    try:
        y_test_bin = label_binarize(y_test_final, classes=unique_classes_full)
        if len(unique_classes_full) == 2:
            # Binary case usually needs 1 column for roc_auc_score if y_score is 1d, 
            # but label_binarize returns 1 column for binary.
            # probs_final has 2 cols.
            auc_score = roc_auc_score(y_test_final, probs_final[:, 1])
        else:
            auc_score = roc_auc_score(y_test_bin, probs_final, multi_class='ovr', average='macro')
        print(f"AUROC (Macro Average): {auc_score:.4f}")
    except Exception as e:
        print(f"AUROC calculation skipped: {e}")

    # Confusion Matrix
    print("\nConfusion Matrix:")
    cm = confusion_matrix(y_test_final, preds_final, labels=unique_classes_full)
    print(cm)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=unique_classes_full, yticklabels=unique_classes_full)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix (Test Set)')
    plt.tight_layout()
    plt.savefig(os.path.join(output_folder, 'confusion_matrix.png'))
    plt.show()

    # ---------------------------
    # 2. Rare Class Evaluation
    # ---------------------------
    print("\n2. Rare Class Evaluation (<10 patients in total cohort):")
    
    counts = subtype_encoded.value_counts()
    rare_classes = counts[counts < 10].index.tolist()
    
    if rare_classes:
        print(f"Rare classes identified: {rare_classes}")
        # Extract metrics specifically for these classes from classification report logic
        # Or manually compute
        for r_cls in rare_classes:
            # Indices in test set
            r_indices = np.where(y_test_final == r_cls)[0]
            if len(r_indices) > 0:
                r_preds = preds_final[r_indices]
                r_correct = np.sum(r_preds == r_cls)
                r_acc = r_correct / len(r_indices)
                print(f"   Class '{r_cls}': {len(r_indices)} test samples, Accuracy: {r_acc:.2%}")
            else:
                print(f"   Class '{r_cls}': No samples in test set.")
    else:
        print("No classes with <10 patients found.")

    # ---------------------------
    # 3. Visualizations
    # ---------------------------
    print("\n3. Visualizations")
    
    # A. Heatmap of Diffused Prototype Influence (Test Random Selection)
    # We visualize the 'probs_final' (Soft Assignment)
    
    subset_size = min(20, len(probs_final))
    plt.figure(figsize=(10, 6))
    sns.heatmap(probs_final[:subset_size], cmap="viridis", annot=True, fmt=".2f",
                xticklabels=unique_classes_full)
    plt.xlabel("Prototype (Class)")
    plt.ylabel(f"Test Patient (First {subset_size})")
    plt.title("Diffused Prototype Influence (Soft Assignment)")
    plt.tight_layout()
    plt.savefig(os.path.join(output_folder, 'diffused_prototype_influence.png'))
    plt.show()
    
    # B. Graph with Node Colors
    # Resizing network visualization for final report
    # Using the A_final computed earlier
    
    def visualize_final_network():
        G = nx.from_numpy_array(A_final)
        
        # Color nodes by True Label
        # We need integer mapping for colors
        le = LabelEncoder()
        le.fit(unique_classes_full)
        node_colors = le.transform(y_true_all)
        
        pos = nx.spring_layout(G, seed=42)
        
        plt.figure(figsize=(10, 8))
        nx.draw_networkx_nodes(G, pos, node_size=50, node_color=node_colors, cmap='tab10', alpha=0.9)
        nx.draw_networkx_edges(G, pos, alpha=0.1, edge_color='gray')
        
        plt.title(f"Patient Similarity Network (k={k_best})")
        plt.axis('off')
        plt.savefig(os.path.join(output_folder, 'patient_similarity_network.png'))
        plt.show()
        
    visualize_final_network()
    
    # C. Latent Factor Contributions to Prototypes (Barplot)
    # We defined 'final_prototypes'
    
    n_factors = factors.shape[1]
    n_prototypes = len(unique_classes_full)
    
    plt.figure(figsize=(12, 6))
    
    # Prepare data for plotting
    # We plot the absolute value of the prototype centroid vector
    
    bar_width = 0.8 / n_prototypes
    indices = np.arange(n_factors)
    
    for i, cls in enumerate(unique_classes_full):
        proto_vec = final_prototypes[cls]
        # We can plot raw values or absolute values. Raw values show direction.
        plt.bar(indices + i*bar_width, proto_vec, width=bar_width, label=f"Class {cls}", alpha=0.8)
        
    plt.xlabel("Latent Factor Index")
    plt.ylabel("Factor Value (Centroid)")
    plt.title("Latent Factor Contributions to Class Prototypes")
    plt.legend()
    plt.xticks(indices + bar_width * n_prototypes / 2, indices)
    plt.tight_layout()
    plt.savefig(os.path.join(output_folder, 'latent_factor_contributions.png'))
    plt.show()

except Exception as e:
    print(f"Error in Final Evaluation: {e}")
    import traceback
    traceback.print_exc()